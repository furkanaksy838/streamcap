# Streamcap ğŸ¥ğŸ“¡

*Streamcap*, SAP CAP (Cloud Application Programming Model) kullanÄ±larak geliÅŸtirilmiÅŸ bir Ã¶rnek projedir.  
AmacÄ±: *HANA veritabanÄ±ndaki bÃ¼yÃ¼k tablolarÄ± JSON formatÄ±nda streaming (akÄ±ÅŸ) halinde istemciye aktarmak*.  

Bu sayede, milyonlarca satÄ±r veriyi bellek ÅŸiÅŸirmeden, parÃ§a parÃ§a (chunked transfer) istemciye gÃ¶nderebilirsiniz.

## ğŸš€ Ã–zellikler

- ğŸ“Š *HANA veritabanÄ±na baÄŸlanÄ±r* ve tablo verilerini okur  
- ğŸ“¡ *Orders* tablosunu streaming endpoint olarak dÄ±ÅŸa aÃ§ar  
- âš¡ *HTTP chunked transfer* kullanarak satÄ±rlarÄ± parÃ§a parÃ§a gÃ¶nderir  
- ğŸŒ http://localhost:4004/OrdersStream adresinden veriler gerÃ§ek zamanlÄ± gÃ¶rÃ¼lebilir  
- ğŸ†š *HANA vs SQLite farkÄ±nÄ±* gÃ¶sterir â†’ HANA cursor sayesinde streaming destekler, SQLite ise tÃ¼m veriyi tek seferde yÃ¼kler

  > ğŸ’¡ *Neden HANA destekler, SQLite desteklemez?*  
>
> - *HANA*: Kurumsal bir veritabanÄ±dÄ±r. cursor ve fetchSize gibi mekanizmalarla satÄ±rlarÄ± parÃ§a parÃ§a (batch halinde) istemciye gÃ¶ndermeyi destekler.  
>   Bu sayede CAP pipeline() fonksiyonu Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda veriler gerÃ§ekten stream olarak akar.  
>
> - *SQLite: Dosya tabanlÄ±, daha basit bir veritabanÄ±dÄ±r. Cursor mantÄ±ÄŸÄ±nÄ± saÄŸlamaz; sorgu Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda **tÃ¼m tabloyu RAMâ€™e yÃ¼kler* ve tek seferde dÃ¶ner.  
>   Bu yÃ¼zden CAP pipeline() Ã§aÄŸrÄ±sÄ± teknik olarak Ã§alÄ±ÅŸsa da, streaming davranÄ±ÅŸÄ± gÃ¶zlenmez.
>   BU SEBEPLE HANA VERÄ°TABANI KULLANMAMIZ GEREKÄ°R.
>
>## ğŸ“‚ Proje YapÄ±sÄ±

| Yol/Dosya         | AÃ§Ä±klama |
|-------------------|----------|
| *app/*          | UI (Ã¶n yÃ¼z) iÃ§erikleri (varsa Fiori/UI5) |
| *db/*           | Veri modelleri (CDS tanÄ±mlarÄ±, CSV seed datalarÄ±) |
| *srv/*          | Servis tanÄ±mlarÄ± (service.cds, custom logic) |
| *server.js*     | Streaming endpoint (/OrdersStream) kodu |
| *package.json*  | Proje baÄŸÄ±mlÄ±lÄ±klarÄ± ve scriptler |
| *README.md*     | Proje dokÃ¼mantasyonu |


